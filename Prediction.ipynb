{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostClassifier, CatBoost\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded \"input/y.csv\" with shape: (700, 1)\n",
      "Loaded \"input/merged_with_cat_as_dummy.csv\" with shape: (1000, 219)\n",
      "Loaded \"input/merged_with_cat_as_int.csv\" with shape: (1000, 9)\n",
      "Loaded \"input/merged_with_cat_as_str.csv\" with shape: (1000, 9)\n",
      "Loaded \"input/ED.layer_6.csv\" with shape: (1000, 32)\n",
      "submission.shape: (300, 2)\n"
     ]
    }
   ],
   "source": [
    "def load_arr(name, header=None):\n",
    "    nm = 'input/' + name + '.csv'\n",
    "    arr = pd.read_csv(nm, header=header).values\n",
    "    print(f'Loaded \"{nm}\" with shape: {arr.shape}')\n",
    "    return arr\n",
    "\n",
    "y = load_arr('y')\n",
    "    \n",
    "merged_with_cat_as_dummy = load_arr('merged_with_cat_as_dummy')\n",
    "\n",
    "merged_with_cat_as_int = load_arr('merged_with_cat_as_int')\n",
    "\n",
    "merged_with_cat_as_str = load_arr('merged_with_cat_as_str')\n",
    "\n",
    "latent_features = load_arr('ED.layer_6', header='infer')\n",
    "\n",
    "submission = pd.DataFrame(columns=['item_id', 'category_class'])\n",
    "submission['item_id'] = pd.read_csv('input/test.csv')['item_id']\n",
    "print('submission.shape:', submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(pred_probs, subm_file_prefix):\n",
    "    y_pred_classes = []\n",
    "    for pred_prob in pred_probs:\n",
    "        y_pred_classes.append(np.argmax(pred_prob))\n",
    "\n",
    "    submission['category_class'] = y_pred_classes\n",
    "    print(X.shape, submission.shape)\n",
    "    print(submission.head())\n",
    "    \n",
    "    file_name = subm_file_prefix + '.submission.csv'\n",
    "\n",
    "    submission.to_csv(file_name, index=False)\n",
    "    print(f'Created \"{file_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best Boosting model \n",
    "We will use catboost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (300, 9) submission.shape: (300, 2)\n",
      "   item_id category_class\n",
      "0     6000           None\n",
      "1     5532           None\n",
      "2     6797           None\n",
      "3     3325           None\n",
      "4     5447           None\n"
     ]
    }
   ],
   "source": [
    "X = merged_with_cat_as_int[y.shape[0]:]\n",
    "\n",
    "submission['category_class'] = None\n",
    "print('X.shape:', X.shape, 'submission.shape:', submission.shape)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 (300, 9) (300, 2)\n",
      "   item_id  category_class\n",
      "0     6000               0\n",
      "1     5532               0\n",
      "2     6797               3\n",
      "3     3325               1\n",
      "4     5447               1\n",
      "Created \"catboost.submission.csv\"\n"
     ]
    }
   ],
   "source": [
    "cat_col_idxs = [4, 5, 6, 7, 8]\n",
    "\n",
    "num_ensembles = 5\n",
    "pred_probs = []\n",
    "for i in range(num_ensembles):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(f'models/catboost_{i}')\n",
    "\n",
    "    if i == 0:\n",
    "        pred_probs = model.predict_proba(X)\n",
    "    else:\n",
    "        pred_probs += model.predict_proba(X)\n",
    "    print(i, end=' ')\n",
    "pred_probs /= num_ensembles\n",
    "    \n",
    "create_submission_file(pred_probs, 'catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the Latent Features from the Autoencoder NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 9) (300, 32)\n",
      "X.shape: (300, 41) submission.shape: (300, 2)\n",
      "   item_id category_class\n",
      "0     6000           None\n",
      "1     5532           None\n",
      "2     6797           None\n",
      "3     3325           None\n",
      "4     5447           None\n"
     ]
    }
   ],
   "source": [
    "print(merged_with_cat_as_int[y.shape[0]:].shape, latent_features[y.shape[0]:].shape)\n",
    "X = np.concatenate([merged_with_cat_as_int[y.shape[0]:], latent_features[y.shape[0]:]], axis=1)\n",
    "\n",
    "submission['category_class'] = None\n",
    "print('X.shape:', X.shape, 'submission.shape:', submission.shape)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 (300, 41) (300, 2)\n",
      "   item_id  category_class\n",
      "0     6000               0\n",
      "1     5532               0\n",
      "2     6797               3\n",
      "3     3325               1\n",
      "4     5447               2\n",
      "Created \"catboost.latent_features.submission.csv\"\n"
     ]
    }
   ],
   "source": [
    "cat_col_idxs = [4, 5, 6, 7, 8]\n",
    "\n",
    "num_ensembles = 5\n",
    "pred_probs = []\n",
    "for i in range(num_ensembles):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(f'models/catboost_{i}.latent_features')\n",
    "\n",
    "    if i == 0:\n",
    "        pred_probs = model.predict_proba(X)\n",
    "    else:\n",
    "        pred_probs += model.predict_proba(X)\n",
    "    print(i, end=' ')\n",
    "pred_probs /= num_ensembles\n",
    "\n",
    "create_submission_file(pred_probs, 'catboost.latent_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (300, 219) submission.shape: (300, 2)\n",
      "   item_id category_class\n",
      "0     6000           None\n",
      "1     5532           None\n",
      "2     6797           None\n",
      "3     3325           None\n",
      "4     5447           None\n"
     ]
    }
   ],
   "source": [
    "X = merged_with_cat_as_dummy[y.shape[0]:]\n",
    "\n",
    "submission['category_class'] = None\n",
    "print('X.shape:', X.shape, 'submission.shape:', submission.shape)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 219) (300, 2)\n",
      "   item_id  category_class\n",
      "0     6000               1\n",
      "1     5532               0\n",
      "2     6797               3\n",
      "3     3325               1\n",
      "4     5447               1\n",
      "Created \"keras.submission.csv\"\n"
     ]
    }
   ],
   "source": [
    "model = ks.models.load_model('models/keras.model')\n",
    "pred_probs = model.predict(X)\n",
    "\n",
    "create_submission_file(pred_probs, 'keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NN Model with the Latent Features from the Autoencoder NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (300, 251) submission.shape: (300, 2)\n",
      "   item_id category_class\n",
      "0     6000           None\n",
      "1     5532           None\n",
      "2     6797           None\n",
      "3     3325           None\n",
      "4     5447           None\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([merged_with_cat_as_dummy[y.shape[0]:], latent_features[y.shape[0]:]], axis=1)\n",
    "\n",
    "submission['category_class'] = None\n",
    "print('X.shape:', X.shape, 'submission.shape:', submission.shape)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 251) (300, 2)\n",
      "   item_id  category_class\n",
      "0     6000               1\n",
      "1     5532               0\n",
      "2     6797               3\n",
      "3     3325               1\n",
      "4     5447               1\n",
      "Created \"keras.latent_features.submission.csv\"\n"
     ]
    }
   ],
   "source": [
    "model = ks.models.load_model('models/keras.latent_features.model')\n",
    "pred_probs = model.predict(X)\n",
    "\n",
    "create_submission_file(pred_probs, 'keras.latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
